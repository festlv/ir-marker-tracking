{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triangulation of a point from two images\n",
    "----------------------------------------------------\n",
    "\n",
    "__Inputs:__ \n",
    "\n",
    "$K_1$, $K_2$ - 3x3 camera intrinsic calibration/parameters matrix (depends on focal distance, resolution, optical center, alignment of lens)\n",
    "\n",
    "$D_1$, $D_2$ - 1x5 camera disortion coefficients (assumes pinhole camera model)\n",
    "\n",
    "$p_1$, $p_2$ - 1x2 tracking marker in image coordinates (unrectified/undisorted)\n",
    "\n",
    "$R_2$ - 3x3 rotation matrix with respect to first camera\n",
    "\n",
    "$T_2$ - 1x3 translation vector with respect to first camera\n",
    "\n",
    "__Important intermediate variables:__\n",
    "\n",
    "$P_n$ - 3x4 projection matrix of camera. Equals to [R_n | T_n] $ where | means horizontal stacking\n",
    "\n",
    "\n",
    "Two possible scenarios:\n",
    "\n",
    "1. If image is already undistorted, let $P_n = K_n \\times [R_n | Tn]$ and pass image coordinates to triangulatePoints.\n",
    "2. If image is not undistorted, call undistortPoints to get normalized point coordinates and let $P_n = [R_n | Tn]$ (so that triangulatePoints doesn't use calibration matrix more than once).\n",
    "\n",
    "For better performance, it's better to find markers in raw image and undistort just those points instead of all image (scenario 2).\n",
    "\n",
    "\n",
    "\n",
    "Sequence of steps for scenario 2:\n",
    "\n",
    "1. undisortPoints is called to remove lens disortion with points in image coordinates.\n",
    "2. $P_n = [R_n | T_n]\n",
    "3. triangulatePoints(P_1, P_2, undistorted_p_1, undistorted_p_2) -> P_3D 1x4 matrix. To get world coordinates, divide by last element (Pt = P_3D / P_3D[3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic camera matrix\n",
      "[[ 544.433304    0.        314.924406]\n",
      " [   0.        543.746983  240.672811]\n",
      " [   0.          0.          1.      ]]\n",
      "Disortion coefficients\n",
      "[[ -4.43683000e-01   1.95487000e-01   7.62000000e-04   1.93000000e-04\n",
      "    0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Mat_K = np.matrix([[544.433304, 0, 314.924406], [0, 543.746983, 240.672811],[ 0, 0, 1]])\n",
    "\n",
    "\n",
    "print \"Intrinsic camera matrix\"\n",
    "print Mat_K\n",
    "\n",
    "Mat_D = np.matrix([-0.443683, 0.195487, 0.000762, 0.000193, 0])\n",
    "\n",
    "print \"Disortion coefficients\"\n",
    "\n",
    "print Mat_D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.55466002  0.0307961 ]]]\n",
      "[[[ 0.0359632   0.02101111]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "from numpy.linalg import inv\n",
    "\n",
    "#p_1 = np.array([[[321.05,267.23]]], dtype=np.float32)\n",
    "\n",
    "#p_2 = np.array([[[53.19, 261.80]]], dtype=np.float32)\n",
    "\n",
    "p_1 = np.array([[[581.30,255.57]]], dtype=np.float32)\n",
    "\n",
    "p_2 = np.array([[[334.49, 252.09]]], dtype=np.float32)\n",
    "\n",
    "p_1_undistorted = cv2.undistortPoints(p_1, Mat_K, Mat_D)\n",
    "\n",
    "p_2_undistorted = cv2.undistortPoints(p_2, Mat_K, Mat_D)\n",
    "\n",
    "print p_1_undistorted\n",
    "\n",
    "print p_2_undistorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_1\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]]\n",
      "P_2\n",
      "[[ 1.   0.   0.  -0.5]\n",
      " [ 0.   1.   0.   0. ]\n",
      " [ 0.   0.   1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Construct projection matrices of both cameras\"\"\"\n",
    "\n",
    "P_1 = np.hstack((np.eye(3), np.matrix([0, 0, 0]).T))\n",
    "\n",
    "R12 = np.eye(3) # no rotation for cameras\n",
    "\n",
    "T12 = np.matrix([-0.5, 0, 0])\n",
    "\n",
    "P_2 = np.hstack((R12, T12.T))\n",
    "\n",
    "\n",
    "\n",
    "print \"P_1\"\n",
    "\n",
    "print P_1\n",
    "\n",
    "print \"P_2\"\n",
    "print P_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.53462042]\n",
      " [ 0.0249656 ]\n",
      " [ 0.96377878]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "Pt_3D = cv2.triangulatePoints(P_1, P_2, np.array([0.5546600, 0.0307961]),np.array([0.0359632, 0.02101111]) )\n",
    "\n",
    "print Pt_3D / Pt_3D[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
